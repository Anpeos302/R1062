---
title: "2_3 Read JSON"
author: "Ji-Lung Hsieh"
output:
  html_notebook:
    number_sections: true
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    fig_width: 8
    fig_height: 4
    fig_caption: true
    theme: united
    highlight: tango
---
# Introduction
* Slide: https://docs.google.com/presentation/d/e/2PACX-1vTFRVkwdscR3QNdVD6Q8JEKshlORtgdP_DUq19HPjbO6_8nN3ADTEtxuOr_Z28t3HKGdf9_m3icULpO/pub?start=false&loop=false&delayms=3000&slide=id.g2074c710b4_0_302
* Youtube: https://www.youtube.com/playlist?list=PLK0n8HKZQ_VfJcqBGlcAc0IKoY00mdF1B



```{r importing packages}
pkgs <- c("jsonlite", "httr")
pkgs <- pkgs[!(pkgs %in% installed.packages()[,"Package"])] 
if(length(pkgs)) install.packages(pkgs)

library(httr)
library(jsonlite)
options(stringsAsFactors = F)
```


# Read well-formatted json
* Cases: Open data: Hospital revisits https://data.gov.tw/dataset/18585
* jsonlite::fromJSON() converts JSON to R objects, will be a list or a data.frame.
* If the json is a well-formmatted json (which is a square bracket contains several curly brackets), it will be converted to a data.frame. If not, it will be converted to a list.

```{r warning=FALSE}
# the url is a character variable, not a vector
url <- "http://data.nhi.gov.tw/Datasets/DatasetResource.ashx?rId=A21030000I-E30008-002&ndctype=JSON&ndcnid=18585"

df <- fromJSON(content(GET(url), "text"))
str(df)
```


## GET() to deliver a request and receive a response

```{r GET()}
response <- GET(url)
class(response)
??httr::GET
```

## Extract content from a request 

* content {httr}: Extract content from a request, and convert to a string (character).
* There are currently three ways to retrieve the contents of a request: as a raw object (as = "raw"), as a character vector, (as = "text"), and as parsed into an R object where possible, (as = "parsed"). If as is not specified, content does its best to guess which output is most appropriate.

```{r httr::content()}
text <- content(response, "text")
class(text)
??httr::content
```

## jsonlite::fromJSON converts string to R objects
* Dealing with BOM: https://www.r-bloggers.com/dealing-with-a-byte-order-mark-bom/

```{r}
df.test <- fromJSON(text)
?fromJSON
```


# Practice 01
* Read json data in following urls

```{r}

url_AQI <- "http://opendata.epa.gov.tw/ws/Data/REWIQA/?$orderby=SiteName&$skip=0&$top=1000&format=json"
url_foodRumor <- "http://data.fda.gov.tw/cacheData/159_3.json"
url_ubike <- "http://data.taipei/youbike"
url_rent591 <- "https://rent.591.com.tw/home/search/rsList?is_new_list=1&type=1&kind=2&searchtype=1&region=1"
url_dcard <- "https://www.dcard.tw/_api/forums/girl/posts?popular=true"
url_cht <- "https://www.googleapis.com/customsearch/v1element?key=AIzaSyCVAXiUzRYsML1Pv6RwSG1gunmMikTzQqY&rsz=1&num=20&hl=zh_TW&prettyPrint=false&source=gcsc&gss=.com&sig=0c3990ce7a056ed50667fe0c3873c9b6&cx=013510920051559618976:klsxyhsnf7g&q=%E9%85%92%E9%A7%95&lr=&filter=1&sort=&googlehost=www.google.com&callback=google.search.Search.apiary7677&nocache=1481218832065"
url_pchome <- "http://ecshweb.pchome.com.tw/search/v3.3/all/results?q=X100F&page=1&sort=rnk/dc"
url_udn <- "https://video.udn.com/realtime/general"
url_104 <- "https://www.104.com.tw/jobs/search/list?ro=0&keyword=%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90&area=6001001000&order=1&asc=0&kwop=7&page=2&mode=s&jobsource=n104bank1"
res <- fromJSON(content(GET(url), "text"))
```



# JSON Cases

## Well-formatted JSON AQI
* A `[]` contains `{}` pairs

```{r}
url_AQI <- "http://opendata.epa.gov.tw/ws/Data/REWIQA/?$orderby=SiteName&$skip=0&$top=1000&format=json"
res <- fromJSON(content(GET(url_AQI), "text"))
dim(res)
str(res)
```

## Hierarchical JSON. rent591

```{r}
url_rent591 <- "https://rent.591.com.tw/home/search/rsList?is_new_list=1&type=1&kind=2&searchtype=1&region=1"
# response <- GET(url_rent591, write_disk("data/rent591_original.json", overwrite=TRUE))
res <- fromJSON(content(GET(url_rent591), "text"))
# access the right data.frame node
View(res$data$data)
```


## Non-typical json: food rumor
* non-typical json, not a [] containing {} pairs
* It will converted to a list containing list, ...
* You can try to convert it to a data.frame to see what happens 
`safefood.df <- as.data.frame(safefood)`
* You can try to get it back to your disk then open it by any editor on your local computer.
`file <- GET(url, write_disk("../data/safefood.json", overwrite=TRUE))`

```{r, message=FALSE, warning=FALSE}
url <- 'http://data.fda.gov.tw/cacheData/159_3.json'
safefood <- fromJSON(content(GET(url),'text'))
# str(safefood)
class(safefood)
```

### unlist() the list to a long vector

```{r}
# unlist() converts (de-stractify) a list to a vector
safefood.v <- unlist(safefood)
head(safefood.v, n=20)
```

### remove NAs

```{r}
# check if NAs exist
sum(is.na(safefood.v))

# remove NAs
safefood.v <- safefood.v[!is.na(safefood.v)]
# length(safefood.v)

# double-check NAs
sum(is.na(safefood.v))

# by anyNA()
anyNA(safefood.v)
```

### vector -> matrix -> data.frame
* `matrix()` convert vector to matrix
* `as.data.frame()` convert a matrix to a data.frame

```{r}
safefood.m <- matrix(safefood.v, byrow = T, ncol = 5)
?matrix
# convert matrix to dataframe
safefood.df <- as.data.frame(safefood.m)
```

### Clean and name the data.frame

```{r}
# delete the 4th column
safefood.df <- safefood.df[-4]

# naming the data.frame
names(safefood.df) <- c('category', 'question', 'answer', 'timestamp')
```


# Cleaning and formatting the data

## String substitution to clean character vector

```{r}
# replace all characters between <> in non-greedy search
safefood.df$answer <- gsub("<.*?>", "", safefood.df$answer)

# replace all space characters including \n \t
safefood.df$answer <- gsub("\\s", "", safefood.df$answer)

# replace specified words
safefood.df$answer <- gsub("解答：", "", safefood.df$answer)

# replace questions befor (1)
# safefood.df$answer <- gsub("^.*\\(1\\)", "(1)", safefood.df$answer)
# answer.lens <- sapply(safefood.df$answer, nchar)
# summary(answer.lens)

safefood.df$answer

```

## Creating a function to clean the character vector

```{r}

cleanFun <- function(htmlString) {
  htmlString <- gsub("<.*?>", "", htmlString)
  htmlString <- gsub("&nbsp;", "", htmlString)
  htmlString <- gsub("解答：", "", htmlString)
  return(htmlString)
}

safefood.df$answer <- cleanFun(safefood.df$answer)

```



## Embedded in javascript code

```{r}
url <- "https://www.googleapis.com/customsearch/v1element?key=AIzaSyCVAXiUzRYsML1Pv6RwSG1gunmMikTzQqY&rsz=1&num=20&hl=zh_TW&prettyPrint=false&source=gcsc&gss=.com&sig=0c3990ce7a056ed50667fe0c3873c9b6&cx=013510920051559618976:klsxyhsnf7g&q=%E9%85%92%E9%A7%95&lr=&filter=1&sort=&googlehost=www.google.com&callback=google.search.Search.apiary7677&nocache=1481218832065"
text <- content(GET(url), 'text')
head(text)
text
text <- substr(text, 49, nchar(text)-2)
res <- fromJSON(text)
View(res$results)
```


# Timestamp conversion

## Converting character to POSIXlt

```{r}
# ?strptime
# ?format
# ?POSIXct
# ?POSIXlt

# convert strings to time objects by specified format
safefood.df$ltime <- strptime(safefood.df$timestamp, "%m %e %Y")
class(safefood.df$ltime)
```

## Accessing temporal features of timestamps 

```{r}
# safefood.df$ltime$hour
head(safefood.df$ltime$mday)
head(safefood.df$ltime$month)
head(safefood.df$ltime$year) # year since 1900
head(safefood.df$ltime$wday) # 0~6 day of the week
head(safefood.df$ltime$yday) # 0~365 day of the year
head(safefood.df$ltime$zone) # ChungYuan Standard Time
class(as.Date("2017-01-01"))
class(as.POSIXct("2017-01-08"))
```

## Converting numeric to POSIXct

```{r}
z <- 7.343736909722223e5
as.POSIXct((z - 719529)*86400, origin = "1970-01-01", tz = "UTC")
as.POSIXlt((z - 719529)*86400, origin = "1970-01-01", tz = "Asia/Taipei")

as.POSIXct(Sys.time(), tz="CST")
as.POSIXct(Sys.time(), tz="Asia/Taipei")
as.POSIXlt(Sys.time(), tz="CST")
as.POSIXlt(Sys.time(), tz="America/New_York")
as.POSIXlt(Sys.time(), tz="Asia/Taipei")
as.POSIXlt(Sys.time(), tz="Asia/Tokyo")

```

## POSIXct functions
* time zone converter 
* http://www.timezoneconverter.com/cgi-bin/zoneinfo?tz=America/New_York
* GMT: Greenwich Mean Time (is not verified scientifically)
* UTC: Coordinated Universal Time (closed to GMT in most of circumstance)

```{r}
class(safefood.df$ltime)	# POSIXlt
safefood.df$ctime <- as.POSIXct(safefood.df$ltime) # POSIXct

months(safefood.df$ctime)
weekdays(safefood.df$ltime)
sort(safefood.df$ctime)
sort(safefood.df$ltime)

Sys.setlocale("LC_ALL", "C")
format(safefood.df$ctime, "%m-%d-%Y")
```

## Get current system time

```{r}
Sys.time()
Sys.Date()

start <- proc.time()

# your code

proc.time() - start

```



# Appendix: Downloading JSON files

```{r}
url <- 'http://data.nhi.gov.tw/Datasets/DatasetResource.ashx?rId=A21030000I-E30008-002&ndctype=JSON&ndcnid=18585'
res <- GET(url, write_disk("../data/hospital_retreat.json", overwrite=TRUE))
library(jsonlite)
test2 <- fromJSON(res$request$output$path)

url <- 'http://data.fda.gov.tw/cacheData/159_3.json'
GET(url, write_disk("../data/safefood.json", overwrite=TRUE))

url <- "http://data.taipei/youbike"
GET(url, write_disk("../data/ubikeSample.json", overwrite=TRUE))

```

